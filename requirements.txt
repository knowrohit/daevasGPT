git+https://github.com/EleutherAI/DeeperSpeed.git#egg=deepspeed
ftfy>=6.0.1
git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836
huggingface_hub>=0.11.0
lm_eval>=0.3.0
numpy>=1.22.0
pybind11>=2.6.2
regex
streamlit
sacremoses
six
tiktoken>=0.1.2
tokenizers>=0.12.1
transformers>=4.24.0
autopep8>=1.5.6
clang-format>=13.0.1
pre-commit>=2.17.0
pytest>=6.2.3
pytest-cov>=2.11.1
pytest-forked>=1.3.0
pytest-xdist
bitsandbytes
datasets
loralib
sentencepiece
git+https://github.com/huggingface/transformers.git
git+https://github.com/huggingface/peft.git
gradio==3.20.0
torch -f https://download.pytorch.org/whl/cpu/torch_stable.html
cpm_kernels==1.0.11
pyngrok
sshtunnel
bingbong
git+https://github.com/huggingface/optimum.git
tokenizers==0.13.3
wandb
Flask
einops
gradio
torch
transformers
numpy
sentencepiece
# triton==2.0.0.dev20221202
# -e git+https://github.com/samhavens/just-triton-flash.git#egg=flash_attn
# RuntimeError: Triton requires CUDA 11.4+